<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>Daniel P. Quinn</title><meta name="next-head-count" content="3"/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a54b4f32bdc1ef890ddd.js"></script><script src="/_next/static/chunks/webpack-61f1b6d34e7ba415b8c1.js" defer=""></script><script src="/_next/static/chunks/framework-895f067827ebe11ffe45.js" defer=""></script><script src="/_next/static/chunks/main-b9780dc6f4fa7abb3771.js" defer=""></script><script src="/_next/static/chunks/pages/_app-76f68770679821db743d.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bid%5D-ed8a1c1d247a5bbba654.js" defer=""></script><script src="/_next/static/OJKJPB7h_rkE15QK9wh6b/_buildManifest.js" defer=""></script><script src="/_next/static/OJKJPB7h_rkE15QK9wh6b/_ssgManifest.js" defer=""></script></head><body><div id="__next"><h1><a href="/">Daniel P. Quinn</a></h1><article><time datetime="2021-08-17">2021-08-17</time><h2>Code Sketch - Audio Flow</h2><br/><div><video autoplay loop controls>
  <source src="/assets/2021-08/audio-flow.mp4" type="video/mp4">
</video>
<p><a href="https://nannou.cc/">Nannou</a> source code:</p>
<pre><code>use nannou::noise::*;
use std::sync::mpsc;
use nannou::prelude::*;
use nannou_audio as audio;
use nannou_audio::Buffer;
use ringbuf::{Consumer, Producer, RingBuffer};

fn main() {
    nannou::app(model)
        .update(update)
        .run();
}

struct InputModel {
    producer: Producer&#x3C;f32>,
}

struct OutputModel {
    tx: mpsc::Sender&#x3C;f32>,
    consumer: Consumer&#x3C;f32>,
}

struct Particle {
    pos: Vec2,
    vel: Vec2,
}

impl Particle {
    fn new(x: f32, y: f32) -> Particle {
        Particle {
            pos: vec2(x, y),
            vel: vec2(0.0, 0.0),
        }
    }

    fn update(&#x26;mut self, dir: Vec2, max: f32) {
        self.pos += self.vel;
        self.vel += dir / 50.0 * (max * 100.0);
        self.vel *= 0.95;
    }
}

struct Model {
    scale: u32,
    cols: u32,
    rows: u32,
    noise: Perlin,
    particles: Vec&#x3C;Particle>,
    vectors: Vec&#x3C;Vec2>,
    max: f32,
    amplitudes: Vec&#x3C;f32>,
    rx: mpsc::Receiver&#x3C;f32>,
    in_stream: audio::Stream&#x3C;InputModel>,
    out_stream: audio::Stream&#x3C;OutputModel>,
}

fn model(app: &#x26;App) -> Model {
    // Create a new window! Store the ID so we can refer to it later.
    let width = 200;
    let height = 200;
    let scale = 10;
    app.new_window()
        .size(width, height)
        .view(view)
        .build()
        .unwrap();
    let win_r = app.main_window().rect();
    let cols = width / scale;
    let rows = height / scale;
    let mut noise = Perlin::new();
    noise = noise.set_seed(1);
    let mut vectors = vec![];
    for _i in 0..(rows * cols) {
        vectors.push(vec2(0.1, 0.1));
    }
    let mut particles = vec![];
    for _i in 0..500 {
        let x = map_range(random(), 0.0, 1.0, win_r.left(), win_r.right());
        let y = map_range(random(), 0.0, 1.0, win_r.bottom(), win_r.top());
        particles.push(Particle::new(x, y));
    }

    // Initialise the audio host so we can spawn an audio stream.
    let audio_host = audio::Host::new();

    // Create a ring buffer and split it into producer and consumer
    let latency_samples = 1024;
    let ring_buffer = RingBuffer::&#x3C;f32>::new(latency_samples * 2); // Add some latency
    let (mut prod, cons) = ring_buffer.split();
    for _ in 0..latency_samples {
        // The ring buffer has twice as much space as necessary to add latency here,
        // so this should never fail
        prod.push(0.0).unwrap();
    }

    let (tx, rx) = mpsc::channel();

    // Create input model and input stream using that model
    let in_model = InputModel { producer: prod };
    let in_stream = audio_host
        .new_input_stream(in_model)
        .capture(pass_in)
        .build()
        .unwrap();

    // Create output model and output stream using that model
    let out_model = OutputModel { consumer: cons, tx };
    let out_stream = audio_host
        .new_output_stream(out_model)
        .render(pass_out)
        .build()
        .unwrap();

    in_stream.play().unwrap();
    out_stream.play().unwrap();

    Model {
        scale,
        cols,
        rows,
        noise,
        particles,
        vectors,
        max: 0.0,
        amplitudes: [0.0; 10].to_vec(),
        rx,
        in_stream,
        out_stream,
    }
}

fn pass_in(model: &#x26;mut InputModel, buffer: &#x26;Buffer) {
    for frame in buffer.frames() {
        for sample in frame {
            model.producer.push(*sample).ok();
        }
    }
}

fn pass_out(model: &#x26;mut OutputModel, buffer: &#x26;mut Buffer) {
    for frame in buffer.frames_mut() {
        for sample in frame {
            let recorded_sample = match model.consumer.pop() {
                Some(f) => f,
                None => 0.0,
            };
            *sample = recorded_sample;
            if recorded_sample > 0.0 {
                model.tx.send(recorded_sample).unwrap();
            }
        }
    }
}

fn key_pressed(_app: &#x26;App, model: &#x26;mut Model, key: Key) {
    match key {
        Key::Space => {
            if model.in_stream.is_paused() {
                model.in_stream.play().unwrap();
                model.out_stream.play().unwrap();
            } else {
                model.in_stream.pause().unwrap();
                model.out_stream.pause().unwrap();
            }
        }
        _ => {}
    }
}

fn update(app: &#x26;App, model: &#x26;mut Model, _update:Update) {
    let win = app.main_window();
    let win_r = win.rect();
    let width = win_r.right() - win_r.left();
    let height = win_r.top() - win_r.bottom();
    let mut yoff = 0.0;
    let zoff = app.time / 5.0;

    model.max *= 0.9;

    for x in model.rx.try_iter() {
        if x > model.max {
            model.max = x;
        }
    }

    for col in 0..model.cols {
        let mut xoff = 0.0;
        for row in 0..model.rows {
            let random = model.noise.get([xoff as f64, yoff as f64, zoff as f64]);
            let angle = map_range(random, 0.0, 1.0, 0.0, 360.0).to_radians();
            model.vectors[(row * model.cols + col) as usize] = vec2(0.0, 1.0).rotate(angle as f32);
            xoff += 0.1;
        }
        yoff += 0.1;
    }

    for particle in &#x26;mut model.particles {
        if particle.pos[0] &#x3C;= win_r.left() {
            particle.pos[0] = win_r.right() - 1.0;
        } else if particle.pos[0] >= win_r.right() {
            particle.pos[0] = win_r.left();
        }
        if particle.pos[1] &#x3C;= win_r.bottom() {
            particle.pos[1] = win_r.top() - 1.0;
        } else if particle.pos[1] >= win_r.top() {
            particle.pos[1] = win_r.bottom();
        }

        let mapped_x = map_range(particle.pos[0], win_r.left(), win_r.right(), 0.0, width);
        let mapped_y = map_range(particle.pos[1], win_r.bottom(), win_r.top(), 0.0, height);
        let row = (mapped_y / model.scale as f32).floor();
        let col = (mapped_x / model.scale as f32).floor();
        let vec = model.vectors[(row * model.cols as f32 + col) as usize];
        particle.update(vec, model.max);
    }
}

fn view(app: &#x26;App, model: &#x26;Model, frame: Frame) {
    let win = app.main_window();
    let win_r = win.rect();
    let draw = app.draw();
    let width = win_r.right() - win_r.left();
    let height = win_r.top() - win_r.bottom();
    let line_length = width / model.cols as f32;

    if frame.nth() == 0 {
        draw.background().color(BLACK);
    }
    
    draw.rect()
        .w_h(width, height)
        .color(rgba(0.0, 0.0, 0.0, 0.05));

    for col in 0..model.cols {
        for row in 0..model.rows {
            let vec = model.vectors[(row * model.cols + col) as usize];
            let start_x = map_range(col as f32, 0.0, model.cols as f32, win_r.left(), win_r.right());
            let start_y = map_range(row as f32, 0.0, model.rows as f32, win_r.bottom(), win_r.top());
            let start = pt2(start_x, start_y);
            let end = start + pt2(line_length as f32 * vec.angle().cos(), line_length as f32 * vec.angle().sin());
            draw.line()
                .start(start)
                .end(end)
                .weight(1.0)
                .color(hsl(model.max, 1.0, 0.05));
        }
    }

    for particle in &#x26;model.particles {
        draw.ellipse()
            .xy(particle.pos)
            .w_h(3.0, 3.0)
            .color(hsl(model.max, 1.0, 0.5));
    }

    let size = model.max * 100.0;

    draw.ellipse()
        .w_h(size, size)
        .color(WHITE);

    draw.to_frame(app, &#x26;frame).unwrap();
    
    if frame.nth() &#x3C; 300 {
        let file_path = captured_frame_path(app, &#x26;frame);
        app.main_window().capture_frame(file_path);
    }
}

fn captured_frame_path(app: &#x26;App, frame: &#x26;Frame) -> std::path::PathBuf {
    app.project_path()
        .expect("failed to locate `project_path`")
        .join("frames")
        .join(format!("{:04}", frame.nth()))
        .with_extension("png")
}
</code></pre>
</div></article></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"id":"2021-08-17","contentHtml":"\u003cvideo autoplay loop controls\u003e\n  \u003csource src=\"/assets/2021-08/audio-flow.mp4\" type=\"video/mp4\"\u003e\n\u003c/video\u003e\n\u003cp\u003e\u003ca href=\"https://nannou.cc/\"\u003eNannou\u003c/a\u003e source code:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003euse nannou::noise::*;\nuse std::sync::mpsc;\nuse nannou::prelude::*;\nuse nannou_audio as audio;\nuse nannou_audio::Buffer;\nuse ringbuf::{Consumer, Producer, RingBuffer};\n\nfn main() {\n    nannou::app(model)\n        .update(update)\n        .run();\n}\n\nstruct InputModel {\n    producer: Producer\u0026#x3C;f32\u003e,\n}\n\nstruct OutputModel {\n    tx: mpsc::Sender\u0026#x3C;f32\u003e,\n    consumer: Consumer\u0026#x3C;f32\u003e,\n}\n\nstruct Particle {\n    pos: Vec2,\n    vel: Vec2,\n}\n\nimpl Particle {\n    fn new(x: f32, y: f32) -\u003e Particle {\n        Particle {\n            pos: vec2(x, y),\n            vel: vec2(0.0, 0.0),\n        }\n    }\n\n    fn update(\u0026#x26;mut self, dir: Vec2, max: f32) {\n        self.pos += self.vel;\n        self.vel += dir / 50.0 * (max * 100.0);\n        self.vel *= 0.95;\n    }\n}\n\nstruct Model {\n    scale: u32,\n    cols: u32,\n    rows: u32,\n    noise: Perlin,\n    particles: Vec\u0026#x3C;Particle\u003e,\n    vectors: Vec\u0026#x3C;Vec2\u003e,\n    max: f32,\n    amplitudes: Vec\u0026#x3C;f32\u003e,\n    rx: mpsc::Receiver\u0026#x3C;f32\u003e,\n    in_stream: audio::Stream\u0026#x3C;InputModel\u003e,\n    out_stream: audio::Stream\u0026#x3C;OutputModel\u003e,\n}\n\nfn model(app: \u0026#x26;App) -\u003e Model {\n    // Create a new window! Store the ID so we can refer to it later.\n    let width = 200;\n    let height = 200;\n    let scale = 10;\n    app.new_window()\n        .size(width, height)\n        .view(view)\n        .build()\n        .unwrap();\n    let win_r = app.main_window().rect();\n    let cols = width / scale;\n    let rows = height / scale;\n    let mut noise = Perlin::new();\n    noise = noise.set_seed(1);\n    let mut vectors = vec![];\n    for _i in 0..(rows * cols) {\n        vectors.push(vec2(0.1, 0.1));\n    }\n    let mut particles = vec![];\n    for _i in 0..500 {\n        let x = map_range(random(), 0.0, 1.0, win_r.left(), win_r.right());\n        let y = map_range(random(), 0.0, 1.0, win_r.bottom(), win_r.top());\n        particles.push(Particle::new(x, y));\n    }\n\n    // Initialise the audio host so we can spawn an audio stream.\n    let audio_host = audio::Host::new();\n\n    // Create a ring buffer and split it into producer and consumer\n    let latency_samples = 1024;\n    let ring_buffer = RingBuffer::\u0026#x3C;f32\u003e::new(latency_samples * 2); // Add some latency\n    let (mut prod, cons) = ring_buffer.split();\n    for _ in 0..latency_samples {\n        // The ring buffer has twice as much space as necessary to add latency here,\n        // so this should never fail\n        prod.push(0.0).unwrap();\n    }\n\n    let (tx, rx) = mpsc::channel();\n\n    // Create input model and input stream using that model\n    let in_model = InputModel { producer: prod };\n    let in_stream = audio_host\n        .new_input_stream(in_model)\n        .capture(pass_in)\n        .build()\n        .unwrap();\n\n    // Create output model and output stream using that model\n    let out_model = OutputModel { consumer: cons, tx };\n    let out_stream = audio_host\n        .new_output_stream(out_model)\n        .render(pass_out)\n        .build()\n        .unwrap();\n\n    in_stream.play().unwrap();\n    out_stream.play().unwrap();\n\n    Model {\n        scale,\n        cols,\n        rows,\n        noise,\n        particles,\n        vectors,\n        max: 0.0,\n        amplitudes: [0.0; 10].to_vec(),\n        rx,\n        in_stream,\n        out_stream,\n    }\n}\n\nfn pass_in(model: \u0026#x26;mut InputModel, buffer: \u0026#x26;Buffer) {\n    for frame in buffer.frames() {\n        for sample in frame {\n            model.producer.push(*sample).ok();\n        }\n    }\n}\n\nfn pass_out(model: \u0026#x26;mut OutputModel, buffer: \u0026#x26;mut Buffer) {\n    for frame in buffer.frames_mut() {\n        for sample in frame {\n            let recorded_sample = match model.consumer.pop() {\n                Some(f) =\u003e f,\n                None =\u003e 0.0,\n            };\n            *sample = recorded_sample;\n            if recorded_sample \u003e 0.0 {\n                model.tx.send(recorded_sample).unwrap();\n            }\n        }\n    }\n}\n\nfn key_pressed(_app: \u0026#x26;App, model: \u0026#x26;mut Model, key: Key) {\n    match key {\n        Key::Space =\u003e {\n            if model.in_stream.is_paused() {\n                model.in_stream.play().unwrap();\n                model.out_stream.play().unwrap();\n            } else {\n                model.in_stream.pause().unwrap();\n                model.out_stream.pause().unwrap();\n            }\n        }\n        _ =\u003e {}\n    }\n}\n\nfn update(app: \u0026#x26;App, model: \u0026#x26;mut Model, _update:Update) {\n    let win = app.main_window();\n    let win_r = win.rect();\n    let width = win_r.right() - win_r.left();\n    let height = win_r.top() - win_r.bottom();\n    let mut yoff = 0.0;\n    let zoff = app.time / 5.0;\n\n    model.max *= 0.9;\n\n    for x in model.rx.try_iter() {\n        if x \u003e model.max {\n            model.max = x;\n        }\n    }\n\n    for col in 0..model.cols {\n        let mut xoff = 0.0;\n        for row in 0..model.rows {\n            let random = model.noise.get([xoff as f64, yoff as f64, zoff as f64]);\n            let angle = map_range(random, 0.0, 1.0, 0.0, 360.0).to_radians();\n            model.vectors[(row * model.cols + col) as usize] = vec2(0.0, 1.0).rotate(angle as f32);\n            xoff += 0.1;\n        }\n        yoff += 0.1;\n    }\n\n    for particle in \u0026#x26;mut model.particles {\n        if particle.pos[0] \u0026#x3C;= win_r.left() {\n            particle.pos[0] = win_r.right() - 1.0;\n        } else if particle.pos[0] \u003e= win_r.right() {\n            particle.pos[0] = win_r.left();\n        }\n        if particle.pos[1] \u0026#x3C;= win_r.bottom() {\n            particle.pos[1] = win_r.top() - 1.0;\n        } else if particle.pos[1] \u003e= win_r.top() {\n            particle.pos[1] = win_r.bottom();\n        }\n\n        let mapped_x = map_range(particle.pos[0], win_r.left(), win_r.right(), 0.0, width);\n        let mapped_y = map_range(particle.pos[1], win_r.bottom(), win_r.top(), 0.0, height);\n        let row = (mapped_y / model.scale as f32).floor();\n        let col = (mapped_x / model.scale as f32).floor();\n        let vec = model.vectors[(row * model.cols as f32 + col) as usize];\n        particle.update(vec, model.max);\n    }\n}\n\nfn view(app: \u0026#x26;App, model: \u0026#x26;Model, frame: Frame) {\n    let win = app.main_window();\n    let win_r = win.rect();\n    let draw = app.draw();\n    let width = win_r.right() - win_r.left();\n    let height = win_r.top() - win_r.bottom();\n    let line_length = width / model.cols as f32;\n\n    if frame.nth() == 0 {\n        draw.background().color(BLACK);\n    }\n    \n    draw.rect()\n        .w_h(width, height)\n        .color(rgba(0.0, 0.0, 0.0, 0.05));\n\n    for col in 0..model.cols {\n        for row in 0..model.rows {\n            let vec = model.vectors[(row * model.cols + col) as usize];\n            let start_x = map_range(col as f32, 0.0, model.cols as f32, win_r.left(), win_r.right());\n            let start_y = map_range(row as f32, 0.0, model.rows as f32, win_r.bottom(), win_r.top());\n            let start = pt2(start_x, start_y);\n            let end = start + pt2(line_length as f32 * vec.angle().cos(), line_length as f32 * vec.angle().sin());\n            draw.line()\n                .start(start)\n                .end(end)\n                .weight(1.0)\n                .color(hsl(model.max, 1.0, 0.05));\n        }\n    }\n\n    for particle in \u0026#x26;model.particles {\n        draw.ellipse()\n            .xy(particle.pos)\n            .w_h(3.0, 3.0)\n            .color(hsl(model.max, 1.0, 0.5));\n    }\n\n    let size = model.max * 100.0;\n\n    draw.ellipse()\n        .w_h(size, size)\n        .color(WHITE);\n\n    draw.to_frame(app, \u0026#x26;frame).unwrap();\n    \n    if frame.nth() \u0026#x3C; 300 {\n        let file_path = captured_frame_path(app, \u0026#x26;frame);\n        app.main_window().capture_frame(file_path);\n    }\n}\n\nfn captured_frame_path(app: \u0026#x26;App, frame: \u0026#x26;Frame) -\u003e std::path::PathBuf {\n    app.project_path()\n        .expect(\"failed to locate `project_path`\")\n        .join(\"frames\")\n        .join(format!(\"{:04}\", frame.nth()))\n        .with_extension(\"png\")\n}\n\u003c/code\u003e\u003c/pre\u003e\n","title":"Code Sketch - Audio Flow","date":"2021-08-17"}},"__N_SSG":true},"page":"/posts/[id]","query":{"id":"2021-08-17"},"buildId":"OJKJPB7h_rkE15QK9wh6b","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>